@inproceedings{boeing07,
  series = {GRAPHITE07},
  title = {Evaluation of real-time physics simulation systems},
  url = {http://dx.doi.org/10.1145/1321261.1321312},
  DOI = {10.1145/1321261.1321312},
  booktitle = {Proceedings of the 5th international conference on Computer graphics and interactive techniques in Australia and Southeast Asia},
  publisher = {ACM},
  author = {Boeing,  Adrian and Br\"{a}unl,  Thomas},
  year = {2007},
  month = dec,
  collection = {GRAPHITE07}
}

@InProceedings{haarnoja18,
  title = 	 {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
  author =       {Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {1861--1870},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {10--15 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v80/haarnoja18b/haarnoja18b.pdf},
  url = 	 {https://proceedings.mlr.press/v80/haarnoja18b.html},
  abstract = 	 {Model-free deep reinforcement learning (RL) algorithms have been demonstrated on a range of challenging decision making and control tasks. However, these methods typically suffer from two major challenges: very high sample complexity and brittle convergence properties, which necessitate meticulous hyperparameter tuning. Both of these challenges severely limit the applicability of such methods to complex, real-world domains. In this paper, we propose soft actor-critic, an off-policy actor-critic deep RL algorithm based on the maximum entropy reinforcement learning framework. In this framework, the actor aims to maximize expected reward while also maximizing entropy. That is, to succeed at the task while acting as randomly as possible. Prior deep RL methods based on this framework have been formulated as Q-learning methods. By combining off-policy updates with a stable stochastic actor-critic formulation, our method achieves state-of-the-art performance on a range of continuous control benchmark tasks, outperforming prior on-policy and off-policy methods. Furthermore, we demonstrate that, in contrast to other off-policy algorithms, our approach is very stable, achieving very similar performance across different random seeds.}
}

@misc{schulman2017,
      title={Proximal Policy Optimization Algorithms}, 
      author={John Schulman and Filip Wolski and Prafulla Dhariwal and Alec Radford and Oleg Klimov},
      year={2017},
      eprint={1707.06347},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1707.06347}, 
}

@misc{heess17,
      title={Emergence of Locomotion Behaviours in Rich Environments}, 
      author={Nicolas Heess and Dhruva TB and Srinivasan Sriram and Jay Lemmon and Josh Merel and Greg Wayne and Yuval Tassa and Tom Erez and Ziyu Wang and S. M. Ali Eslami and Martin Riedmiller and David Silver},
      year={2017},
      eprint={1707.02286},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/1707.02286}, 
}

@article{Holden2017,
  title = {Phase-functioned neural networks for character control},
  volume = {36},
  ISSN = {1557-7368},
  url = {http://dx.doi.org/10.1145/3072959.3073663},
  DOI = {10.1145/3072959.3073663},
  number = {4},
  journal = {ACM Transactions on Graphics},
  publisher = {Association for Computing Machinery (ACM)},
  author = {Holden,  Daniel and Komura,  Taku and Saito,  Jun},
  year = {2017},
  month = jul,
  pages = {1–13}
}

@misc{kingma22,
      title={Auto-Encoding Variational Bayes}, 
      author={Diederik P Kingma and Max Welling},
      year={2022},
      eprint={1312.6114},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1312.6114}, 
}

@inproceedings{Lasseter1987,
  series = {SIGGRAPH ’87},
  title = {Principles of traditional animation applied to 3D computer animation},
  url = {http://dx.doi.org/10.1145/37401.37407},
  DOI = {10.1145/37401.37407},
  booktitle = {Proceedings of the 14th annual conference on Computer graphics and interactive techniques},
  publisher = {ACM},
  author = {Lasseter,  John},
  year = {1987},
  month = aug,
  collection = {SIGGRAPH ’87}
}

@misc{tina23,
	author = {Tina Lee},
	title = {Cost of CGI: CGI Scenes in Marvel Universe Movies (2023) --- academyofanimatedart.com},
	howpublished = {\url{https://academyofanimatedart.com/breakthrough-and-expensive-cgi-scenes-in-mcu-movies/}},
	year = {2023},
}

@misc{wagner23,
	author = {Kate Wagner},
	title = {Lessons From the Catastrophic Failure of the Metaverse --- thenation.com},
	howpublished = {\url{https://www.thenation.com/article/culture/metaverse-zuckerberg-pr-hype/}},
	year = {2023},
}

@misc{dexerto24,
	author = {Dexerto},
	title = {Stellar Blade Director talks about the challenge of developing Eve - Dexerto --- dexerto.com},
	howpublished = {\url{https://www.dexerto.com/gaming/stellar-blade-director-talks-about-the-challenge-of-developing-eve-2621380/}},
	year = {2024},
}

@book{survival09,
  author = {Richard Williams},
  title = {Animator's Survival Kit},
  year = {2009},
}

@article{deepmimic,
	author = {Peng, Xue Bin and Abbeel, Pieter and Levine, Sergey and van de Panne, Michiel},
	title = {DeepMimic: Example-guided Deep Reinforcement Learning of Physics-based Character Skills},
	journal = {ACM Trans. Graph.},
	issue_date = {August 2018},
	volume = {37},
	number = {4},
	month = jul,
	year = {2018},
	issn = {0730-0301},
	pages = {143:1--143:14},
	articleno = {143},
	numpages = {14},
	url = {http://doi.acm.org/10.1145/3197517.3201311},
	doi = {10.1145/3197517.3201311},
	acmid = {3201311},
	publisher = {ACM},
	address = {New York, NY, USA},
	keywords = {motion control, physics-based character animation, reinforcement learning},
} 

@article{Fussell2021,
  title = {SuperTrack: motion tracking for physically simulated characters using supervised learning},
  volume = {40},
  ISSN = {1557-7368},
  url = {http://dx.doi.org/10.1145/3478513.3480527},
  DOI = {10.1145/3478513.3480527},
  number = {6},
  journal = {ACM Transactions on Graphics},
  publisher = {Association for Computing Machinery (ACM)},
  author = {Fussell,  Levi and Bergamin,  Kevin and Holden,  Daniel},
  year = {2021},
  month = dec,
  pages = {1–13}
}

@inproceedings{tessler2023calm,
author = {Tessler, Chen and Kasten, Yoni and Guo, Yunrong and Mannor, Shie and Chechik, Gal and Peng, Xue Bin},
title = {CALM: Conditional Adversarial Latent Models for Directable Virtual Characters},
year = {2023},
isbn = {9798400701597},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3588432.3591541},
doi = {10.1145/3588432.3591541},
abstract = {In this work, we present Conditional Adversarial Latent Models (CALM), an approach for generating diverse and directable behaviors for user-controlled interactive virtual characters. Using imitation learning, CALM learns a representation of movement that captures the complexity and diversity of human motion, and enables direct control over character movements. The approach jointly learns a control policy and a motion encoder that reconstructs key characteristics of a given motion without merely replicating it. The results show that CALM learns a semantic motion representation, enabling control over the generated motions and style-conditioning for higher-level task training. Once trained, the character can be controlled using intuitive interfaces, akin to those found in video games.},
booktitle = {ACM SIGGRAPH 2023 Conference Proceedings},
keywords = {reinforcement learning, animated character control, adversarial training, motion capture data},
location = {Los Angeles, CA, USA},
series = {SIGGRAPH '23}
}

@misc{smplx19,
  title={Expressive Body Capture: 3D Hands, Face, and Body from a Single Image}, 
  author={Georgios Pavlakos and Vasileios Choutas and Nima Ghorbani and Timo Bolkart and Ahmed A. A. Osman and Dimitrios Tzionas and Michael J. Black},
  year={2019},
  eprint={1904.05866},
  archivePrefix={arXiv},
  primaryClass={cs.CV},
  url={https://arxiv.org/abs/1904.05866}, 
}

@phdthesis{guiltygear23,
  title={Ready? Fight! How Guilty Gear -Strive-'s approach to fighting game animations lend themselves to character appeal.},
  author={Larsson, Fabian and Strombom, Gustav},
  year={2023},
  school={Uppsala Universitet},
  url = {https://uu.diva-portal.org/smash/get/diva2:1769414/FULLTEXT01.pdf},
}

@book{disneyanimation81,
  title={Disney Animation: The Illusion of Life},
  publisher={Hyperion},
  year={1995},
  author={Thomas, Frank and Johnston, Ollie},
  isbn={0-89659-233-2},
}

@inproceedings{Lee1999,
  series = {SIGGRAPH ’99},
  title = {A hierarchical approach to interactive motion editing for human-like figures},
  url = {http://dx.doi.org/10.1145/311535.311539},
  DOI = {10.1145/311535.311539},
  booktitle = {Proceedings of the 26th annual conference on Computer graphics and interactive techniques  - SIGGRAPH ’99},
  publisher = {ACM Press},
  author = {Lee,  Jehee and Shin,  Sung Yong},
  year = {1999},
  collection = {SIGGRAPH ’99}
}

@inproceedings{Miller2015,
  series = {MIG ’15},
  title = {Carpet unrolling for character control on uneven terrain},
  url = {http://dx.doi.org/10.1145/2822013.2822031},
  DOI = {10.1145/2822013.2822031},
  booktitle = {Proceedings of the 8th ACM SIGGRAPH Conference on Motion in Games},
  publisher = {ACM},
  author = {Miller,  Mark and Holden,  Daniel and Al-Ashqar,  Rami and Dubach,  Christophe and Mitchell,  Kenny and Komura,  Taku},
  year = {2015},
  month = nov,
  collection = {MIG ’15}
}

@inproceedings{AlAsqhar2013,
  series = {SCA ’13},
  title = {Relationship descriptors for interactive motion adaptation},
  url = {http://dx.doi.org/10.1145/2485895.2485905},
  DOI = {10.1145/2485895.2485905},
  booktitle = {Proceedings of the 12th ACM SIGGRAPH/Eurographics Symposium on Computer Animation},
  publisher = {ACM},
  author = {Al-Asqhar,  Rami Ali and Komura,  Taku and Choi,  Myung Geol},
  year = {2013},
  month = jul,
  collection = {SCA ’13}
}

@misc{smplpowerpoint,
  title = {SMPL made simple FAQs},
  author = {Choutas, Vassilis and Black, Michael and Mahmood, Naureen and Ghorbani, Nima and Osman, Ahmed and Bolkart, Timo and Tripathi, Shashank and Kocabas, Muhammed and Keller, Marilyn and Taheri, Omid and Muller, Lea and Patel, Priyanka and Tesch, Joachim},
  url = {https://files.is.tue.mpg.de/black/talks/SMPL-made-simple-FAQs.pdf},
}

@book{Paul1981-ar,
  title     = "Robot manipulators",
  author    = "Paul, Richard P",
  publisher = "MIT Press",
  series    = "Artificial Intelligence",
  month     =  jan,
  year      =  1981,
  address   = "London, England",
  language  = "en"
}